{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B6_Y8bvwUxv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD, Adam\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torchsummary import summary\n",
        "from torchvision import datasets\n",
        "import urllib\n",
        "import torchmetrics\n",
        "from torchmetrics.classification import MulticlassAUROC\n",
        "from torchmetrics.classification import MulticlassF1Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YlYhoZPohol",
        "outputId": "79623dd1-94af-4ee9-b029-76a883f481d7"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# modify the fully connected layer of ResNet18\n",
        "model_res18 = torchvision.models.resnet18(weights = torchvision.models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "for param in model_res18.parameters():\n",
        "    param.requires_grad = False\n",
        "num_ftrs = model_res18.fc.in_features\n",
        "# add a fc layer with 128 nodes\n",
        "model_res18.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1000),\n",
        "    nn.BatchNorm1d(1000), \n",
        "    nn.ReLU(), \n",
        "    nn.Dropout(0.1),\n",
        "    nn.Linear(1000, 500),\n",
        "    nn.BatchNorm1d(500),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.15),\n",
        "    nn.Linear(500,100),\n",
        "    nn.BatchNorm1d(100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100,4))\n",
        "model_res18.to(device)\n",
        "\n",
        "UNet = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
        "    in_channels=3, out_channels=1, init_features=32, pretrained=True)\n",
        "for name, param in UNet.named_parameters():\n",
        "    print(name)\n",
        "for param in UNet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "UNet.conv = nn.Sequential(\n",
        "                            nn.Conv2d(32,10,2,stride=2),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(0.2),\n",
        "                            nn.Conv2d(10,1,2,stride=2),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Flatten(),\n",
        "                            nn.Linear(4096,1000),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(0.2),\n",
        "                            nn.Linear(1000,4))\n",
        "UNet.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gan11YZJnci8"
      },
      "outputs": [],
      "source": [
        "def train_batch(x, y, model, opt, loss_fn):\n",
        "    model.train()\n",
        "    opt.zero_grad()                    # Flush memory  \n",
        "    batch_loss = loss_fn(model(x), y)  # Compute loss\n",
        "    batch_loss.backward()              # Compute gradients\n",
        "    opt.step()                         # Make a GD step\n",
        "    \n",
        "    return batch_loss.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRpB-_ySnjeX"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def accuracy(x, y, model):\n",
        "  \"\"\"\n",
        "  Calculate and return the accuracy. \n",
        "  x: features\n",
        "  y: labels\n",
        "  Return: accuracy\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  prediction = model(x)\n",
        "  argmaxes = prediction.argmax(dim=1) # get the predicted label \n",
        "  f1 = MulticlassF1Score(num_classes=4,average=None).cuda()\n",
        "  f1_score = f1(prediction,y)\n",
        "  auc = MulticlassAUROC(num_classes=4, average=None, thresholds=None).cuda()\n",
        "  auc_score = auc(prediction,y)\n",
        "  s = torch.sum((argmaxes == y).float())/len(y)  # calculate test accuracy\n",
        "  return s.cpu().numpy(),f1_score.cpu().numpy(),auc_score.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo-rrRX8r0nQ"
      },
      "outputs": [],
      "source": [
        "def plot(losses,accuracies,n_epochs):\n",
        "  \"\"\"\n",
        "  Plot the training accuracies and losses over number of epochs \n",
        "  losses: a list of training loss\n",
        "  accuracies: a list of training accuracy\n",
        "  n_epochs: a list of number of epochs\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(13,3))\n",
        "  plt.subplot(121)\n",
        "  plt.title('Training Loss over epochs')\n",
        "  plt.plot(np.arange(n_epochs) + 1, losses)\n",
        "  plt.subplot(122)\n",
        "  plt.title('Training Accuracy over epochs')\n",
        "  plt.plot(np.arange(n_epochs) + 1, accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_f1_auc(f1,auc,n_epochs):\n",
        "  \"\"\"\n",
        "  Plot the training accuracies and losses over number of epochs \n",
        "  losses: a list of training loss\n",
        "  accuracies: a list of training accuracy\n",
        "  n_epochs: a list of number of epochs\n",
        "  \"\"\"\n",
        "  fig, axs = plt.subplots(2, 2)\n",
        "  axs[0, 0].plot(np.arange(n_epochs) + 1, f1[...,0])\n",
        "  axs[0, 0].set_title('Mild Demented')\n",
        "  axs[0, 1].plot(np.arange(n_epochs) + 1, f1[...,1])\n",
        "  axs[0, 1].set_title('Moderate Demented')\n",
        "  axs[1, 0].plot(np.arange(n_epochs) + 1, f1[...,2])\n",
        "  axs[1, 0].set_title('Non Demented')\n",
        "  axs[1, 1].plot(np.arange(n_epochs) + 1, f1[...,3])\n",
        "  axs[1, 1].set_title('Mild Demented')\n",
        "\n",
        "  for ax in axs.flat:\n",
        "    ax.set(xlabel='Epoch', ylabel='F1 Score')\n",
        "  \n",
        "  for ax in axs.flat:\n",
        "    ax.label_outer()\n",
        "  \n",
        "  fig2, axs2 = plt.subplots(2, 2)\n",
        "  axs2[0, 0].plot(np.arange(n_epochs) + 1, auc[...,0])\n",
        "  axs2[0, 0].set_title('Mild Demented')\n",
        "  axs2[0, 1].plot(np.arange(n_epochs) + 1, auc[...,1])\n",
        "  axs2[0, 1].set_title('Moderate Demented')\n",
        "  axs2[1, 0].plot(np.arange(n_epochs) + 1, auc[...,2])\n",
        "  axs2[1, 0].set_title('Non Demented')\n",
        "  axs2[1, 1].plot(np.arange(n_epochs) + 1,auc[...,3])\n",
        "  axs2[1, 1].set_title('Mild Demented')\n",
        "\n",
        "  for ax in axs2.flat:\n",
        "    ax.set(xlabel='Epoch', ylabel='AUC')\n",
        "  \n",
        "  for ax in axs2.flat:\n",
        "    ax.label_outer()\n",
        "  plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJyen-_KLa66"
      },
      "outputs": [],
      "source": [
        "def train(trainset, testset, model, name):\n",
        "  \"\"\"\n",
        "  Train the model with training dataset, and return the training losses, training\n",
        "    accuracies, and number of epochs. \n",
        "  trainset: the processed train data with wanted dimensions\n",
        "  testset:  the processed test data with wanted dimensions\n",
        "  model: a torchvision model\n",
        "  name: the name of the model in string\n",
        "  Return: Testing accuracy, training losses, training accuracies, and number of epochs\n",
        "  \"\"\"\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  # load the data\n",
        "  train_dl = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                          shuffle=True,drop_last=True)\n",
        "  test_dl = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                         shuffle=False,drop_last=True)\n",
        "\n",
        "  # set up loss function and optimization function\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  opt = Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "  # train and record the loss, accuracies for each training epoch\n",
        "  losses, accuracies, n_epochs = [], [], 100\n",
        "  for epoch in range(n_epochs):\n",
        "    running_vloss = 0.0\n",
        "    print(f\"Running epoch {epoch + 1} of {n_epochs}\")\n",
        "  \n",
        "    epoch_losses, epoch_accuracies  = [], []\n",
        "    for batch in train_dl:\n",
        "      # calculate loss\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        batch_loss = train_batch(x, y, model, opt, loss_func)\n",
        "        epoch_losses.append(batch_loss)\n",
        "    epoch_loss = np.mean(epoch_losses)\n",
        "\n",
        "    for batch in train_dl:\n",
        "      # calcualte accuracy \n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        batch_acc, _, _ = accuracy(x, y, model)\n",
        "        epoch_accuracies.append(batch_acc)\n",
        "    \n",
        "    epoch_accuracy = np.mean(epoch_accuracies)\n",
        "    \n",
        "    \n",
        "    print(f\"The training loss and training accuracy is {epoch_loss} and {epoch_accuracy}\")\n",
        "    losses.append(epoch_loss)\n",
        "    accuracies.append(epoch_accuracy)\n",
        "\n",
        "  # calculate the testing accuracy using the model we just trained\n",
        "  epoch_accuracies = []\n",
        "  batch_num = 0.0\n",
        "  f1_batch, auc_batch = 0, 0\n",
        "  for ix, batch in enumerate(test_dl):\n",
        "      x, y = batch\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      batch_acc, batch_f1, batch_auc = accuracy(x, y, model)\n",
        "      epoch_accuracies.append(batch_acc)\n",
        "      f1_batch += batch_f1\n",
        "      auc_batch += batch_auc\n",
        "      batch_num += 1\n",
        "  print(f\"batch number is {batch_num}\")\n",
        "  f1_batch=f1_batch/batch_num\n",
        "  auc_batch=auc_batch/batch_num   \n",
        "  # save the model for future uses\n",
        "  torch.save(model.state_dict(), name+\".pth\")\n",
        "  print(f\"Test accuracy: {np.mean(epoch_accuracies)}\")\n",
        "  return np.mean(epoch_accuracies), losses, accuracies, n_epochs, f1_batch, auc_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9rUp7_0rhL9"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  # transform the images to match the ImageNet image requirementa\n",
        "  transform = transforms.Compose(\n",
        "      [transforms.Resize((256,256)),\n",
        "       transforms.CenterCrop(224),\n",
        "       transforms.RandomHorizontalFlip(0.4),\n",
        "       transforms.RandomVerticalFlip(0.2),\n",
        "       transforms.RandomAffine(40),\n",
        "       transforms.ToTensor(),\n",
        "       transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "       ]) \n",
        "  transform2 = transforms.Compose(\n",
        "      [transforms.Resize((256,256)),\n",
        "       transforms.RandomHorizontalFlip(0.4),\n",
        "       transforms.RandomAffine(180,translate=(0.3,0.3), shear=10),\n",
        "       transforms.ToTensor()\n",
        "       ]) \n",
        "\n",
        "  # save to data folder\n",
        "  trainset = torchvision.datasets.ImageFolder(root='data/train',transform=transform)\n",
        "\n",
        "  testset = torchvision.datasets.ImageFolder(root='data/test',transform=transform)\n",
        "  # a list of initialized models\n",
        "  models = [model_res18]\n",
        "  # the names of the models\n",
        "  names = [\"res_18\"]\n",
        "\n",
        "  test_acc = [] # store the testing accuracy\n",
        "  for model, name in zip(models,names):\n",
        "    acc, losses , accuracies, n_epochs, f1_score, auc_score = train(trainset,testset,model, name)\n",
        "    test_acc.append(acc)\n",
        "    plot(losses, accuracies, n_epochs)\n",
        "    print(f\"f1 scores is {f1_score}\")\n",
        "    print(f\"AUC is {auc_score}\")\n",
        "    plt.show()\n",
        "  \n",
        "  print(f\"The test accuracy is: {test_acc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuZHzPT1smqK"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ResNet18 testing accuracy after 100 epoch is 0.6682692.\n",
        "f1 scores is [0.07342686 0.01508296 0.4341635  0.2828987 ]\n",
        "AUC is [0.01941244 0.02307692 0.04466501 0.02315964]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "      [transforms.Resize((256,256)),\n",
        "       transforms.CenterCrop(224),\n",
        "       transforms.RandomHorizontalFlip(0.4),\n",
        "       transforms.RandomVerticalFlip(0.2),\n",
        "       transforms.RandomAffine(40),\n",
        "       transforms.ToTensor(),\n",
        "       transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "       ]) \n",
        "\n",
        "model_res18.load_state_dict(torch.load(\"res_18.pth\"))\n",
        "model_res18.eval()\n",
        "testset = torchvision.datasets.ImageFolder(root='data/test',transform=transform)\n",
        "test_dl = torch.utils.data.DataLoader(testset, batch_size=1279,shuffle=False,drop_last=True)\n",
        "f1_result,auc_result = 0,0\n",
        "batch_num = 0.0\n",
        "for ix,batch in enumerate(test_dl):\n",
        "      x,y = batch\n",
        "      x,y = x.cuda(),y.cuda()\n",
        "      prediction = model_res18(x)\n",
        "      f1 = MulticlassF1Score(num_classes=4,average=None).cuda()\n",
        "      f1_score = f1(prediction,y)\n",
        "      auc = MulticlassAUROC(num_classes=4, average=None, thresholds=None).cuda()\n",
        "      auc_score = auc(prediction,y)\n",
        "      f1_result+=f1_score.cpu().numpy()\n",
        "      auc_result+=auc_score.cpu().numpy()\n",
        "      batch_num +=1\n",
        "print(f\"average f1 scores is {f1_result/batch_num}\")\n",
        "print(f\"average auc is {auc_result/batch_num}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "d0697aab8a8e62b1089a39e5d5a04c9417d085bc4e4bbd3a2d92e4b0e655099e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
